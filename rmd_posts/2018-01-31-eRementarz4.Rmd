---
layout: post
title: "Materiały ze spotkania eRementarz #4: uczenie maszynowe z pakietem mlr"
modified:
author: michal
categories: blog
excerpt:
tags: []
image:
  feature:
date: 2018-01-31
output:
  md_document:
    variant: markdown_github
---

```{r include = FALSE}
knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE)
```

Pierwsze tegoroczne spotkanie STWUR-a poprowadził Mateusz Staniak, a zorganizował Jarosław Chilimoniuk. Zachęcamy do zapoznania się z materiałami.


## Materiały

[https://github.com/STWUR/eRementarz3](Pełna prezentacja na Githubie)

### Work flow

- Przygotowanie danych (preprocessing)
- Zadanie (task)
- Wybór modelu (benchmark)
- Strojenie parametrów (tuning)
- Ocena modelu

### Dane

```{r dane}
library(mlr)
library(dplyr)
library(ggplot2)

mieszkania <- read.csv("https://raw.githubusercontent.com/STWUR/STWUR-2017-06-07/master/data/mieszkania_dane.csv") %>%
  filter(!is.na(cena_m2))

head(mieszkania)
```

### Przygotowanie danych

Typowe zadania:

- standaryzacja danych - `normalizeFeatures`
- łączenie mało licznych poziomów zmiennych jakościowych - `mergeSmallFactorLevels`
- wybranie części obserewacji - `subsetTask`
- imputacja danych brakujących - `impute`
- i inne...

### Zadania (task)

- Obsługiwane klasy problemów
```{r taski, eval = F}
makeClassifTask()
makeRegrTask()
makeClusterTask()
makeCostSensTask()
makeMultilabelTask()
makeSurvTask()
```

### Nasz problem

```{r task_regr}
m2_task <- makeRegrTask(id = "mieszkanie",
                        data = mieszkania,
                        target = "cena_m2")
```

- Alternatywnie

```{r task_regr_nasz}
m2_task_ndz <- makeRegrTask(id = "mieszkanie_ndz",
                            data = select(mieszkania, -dzielnica),
                            target = "cena_m2")
```

#### Uwaga

- `fixup.data = "warn"`: czyszczenie danych (aktualnie tylko usuwanie pustych poziomów)
- `check.data = TRUE`: sprawdzanie poprawności danych (aktualnie: NA i puste poziomy zmiennej odpowiedzi)

### Metody uczenia (learner)

- Ogromna liczba dostępnych metod

```{r methods}
listLearners(obj = "regr")[1:6, c(1, 3:4)]
```

- Jak radzi sobie zwykła regresja liniowa?

```{r reglin}
reg_lm <- makeLearner("regr.lm")
```

- A jak inne popularne metody?

```{r otherms}
reg_rf <- makeLearner("regr.randomForest")
reg_nnet <- makeLearner("regr.nnet")
```

- Inaczej:

```{r lrns}
lrns <- makeLearners(c("lm", "randomForest", "nnet"),
                    type = "regr")
```

- takie wywołania tworzą obiekty typu `Learner`
- metody są zaimplementowane w odpowiednich pakietach - `mlr` jest nakładką
- różne metody - różne wsparcie dla brakujących wartości, wag itd

- Uwaga: w ten sposób wszystkie hiperparametry mają ustawione wartości domyślne

#### Informacje o metodzie

```{r prop}
getLearnerProperties(reg_rf)
```

```{r hyperprop}
getLearnerParamSet(reg_rf)
```

### Ustawianie hiperparametrów

- przy tworzeniu learnera:

```{r create}
reg_rf2 <- makeLearner("regr.randomForest",
                       par.vals = list(ntree = 1000))
```

- po utworzeniu learnera:

```{r add}
reg_rf2 <- setHyperPars(reg_rf, ntree = 1000)
```

```{r check}
getHyperPars(reg_rf2)
```

### Porównywanie modeli

```{r bench, eval = FALSE}
porownanie <- benchmark(learners = list(reg_lm, reg_rf, reg_nnet),
                        tasks = list(m2_task, m2_task_ndz),
                        resampling = cv5)
save(porownanie, file = "porownanie.rda")
```

```{r loadbench}
load("porownanie.rda")
porownanie
```

#### Wyniki porównania

```{r wynikpor}
# getBMRAggrPerformances(porownanie)
# getBMRPerformances(porownanie)
plotBMRBoxplots(porownanie)
```

#### Różne kryteria

```{r miary}
listMeasures(obj = "regr")
```

### Wytrenowanie pojedynczego modelu

- podstawowe wywołanie:

```{r rftrain, eval = FALSE}
m2_rf <- train(reg_rf2, m2_task)
```

```{r zapis, echo = FALSE, eval = FALSE}
save(m2_rf, file = "m2_rf.rda")
save(m2_rf_czesc, file = "m2_rf_czesc.rda")
```

- uwaga: można samodzielnie zdefiniować zbiór uczący

```{r sameliczby}
uczacy <- sample(1:nrow(mieszkania), floor(0.7*nrow(mieszkania)))
testowy <- setdiff(1:nrow(mieszkania), uczacy)
```

```{r rfuczacy, eval = FALSE}
m2_rf_czesc <- train(reg_rf2, m2_task, subset = uczacy)
```

```{r wczyt, echo = FALSE}
load("m2_rf.rda")
load("m2_rf_czesc.rda")
```

- przewidywane wartości:

```{r pred}
pred <- predict(m2_rf, task = m2_task)
head(getPredictionResponse(pred))
pred2 <- predict(m2_rf_czesc, newdata = mieszkania[testowy, ])
head(getPredictionResponse(pred2))
```

### Strojenie parametrów

```{r tune1}
all_params <- makeParamSet(
  makeDiscreteParam("mtry", values = 2:5),
  makeDiscreteParam("nodesize", values = seq(5, 45, by = 10))
)
```

```{r tune2, eval = FALSE}
m2_params <- tuneParams(reg_rf2, task = m2_task,
                        resampling = cv3,
                        par.set = all_params,
                        control =  makeTuneControlGrid())
```

```{r wczyt2, echo = FALSE}
load("m2_params.rda")
```

#### Wynik

```{r wyswietlpar, fig.width = 15}
m2_params
par_data <- generateHyperParsEffectData(m2_params)
plotHyperParsEffect(par_data, x = "mtry", y = "nodesize", z = "mse.test.mean", plot.type = "heatmap")
reg_rf2 <- setHyperPars(reg_rf2, mtry = 3)
```

```{r trenujznow, eval = F}
m2_rf2 <- train(reg_rf2, m2_task)
```

```{r wczyt222, echo = F}
load("m2_rf2.rda")
```

#### Inne kontrolki

```{r kontrolki, eval = F}
makeTuneControlCMAES()
makeTuneControlIrace()
makeTuneControlRandom()
```

### Cena mieszkania

```{r cena}
moje <- data.frame(n_pokoj = 3L,
                   metraz = 60.00,
                   rok = 2010L,
                   pietro = 3L,
                   pietro_maks = 5L,
                   dzielnica = "Srodmiescie")
moje$dzielnica <- factor(moje$dzielnica,
                         levels = levels(mieszkania$dzielnica))
predict(m2_rf2, newdata = moje)
```

### Wizualizacja modelu

```{r pdp, eval = F}
pdp <- generatePartialDependenceData(m2_rf2,
                                     m2_task,
                                     features = colnames(mieszkania)[-c(3, 7)])
```

```{r zapis333, echo = F, eval = F}
save(pdp, file = "pdp.rda")
```

```{r wczyt333, echo = F}
load("pdp.rda")
```

```{r plotpdp, fig.width = 15}
plotPartialDependence(pdp)
```

### Podsumowanie

- Tworzenie zadania: `makeRegrTask`, `makeClassifTask` itd
- Metoda uczenia: `makeLearner`, `makeLearners`
- Porównanie kilku modeli: `benchmark`
- Ustawianie hiperparametrów: `setHyperPars`
- Wytrenowanie pojedynczego modelu: `train`
- Strojenie parametrów: `tuneParams`

### Podziękowanie

Dziękujemy firmie Kruk i Wydziałowi Biotechnologii UWr.

